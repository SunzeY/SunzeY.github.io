<!doctype html>
<html>
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Existing styles and scripts -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
    <script type="module" src="https://cdn.jsdelivr.net/npm/ionicons@6/dist/ionicons/ionicons.esm.js"></script>
    <script nomodule src="https://cdn.jsdelivr.net/npm/ionicons@6/dist/ionicons/ionicons.js"></script>
    <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.1.1/model-viewer.min.js"></script>
    <title>Make-it-Real</title>
    <!-- Your new styles -->
    <link rel="stylesheet" href="styles.css">
  </head>
<body>
  <section class="section">

  <div class="container has-text-centered">
    <!-- paper title -->
    <p class="title is-2"> Make-it-Real: Unleashing Large Multimodal Model's Ability for <br> Painting 3D Objects with Realistic Materials </p><br>
    <!-- publication -->
    <!-- <p class="subtitle is-4"> SIGGRAPH Asia 2023 (Conference Track) </p> -->
    <!-- authors -->
    <p class="title is-5 mt-2"> 
      <a href="https://github.com/Aleafy" target="_blank">Ye Fang</a>*<sup>1,4</sup>, 
      <a href="https://github.com/SunzeY/" target="_blank">Zeyi Sun</a>*<sup>2,4</sup>, 
      <a href="https://wutong16.github.io/" target="_blank">Tong Wu</a><sup>3,4</sup>, 
      <a href="https://myownskyw7.github.io/" target="_blank">Jiaqi Wang</a><sup>4</sup>,
      <a href="https://liuziwei7.github.io/" target="_blank">Ziwei Liu</a><sup>5</sup>,
      <a href="https://stanford.edu/~gordonwz/" target="_blank">Gordon Wetzstein</a><sup>6</sup>,
      <a href="http://dahua.me/" target="_blank">Dahua Lin</a><sup>&#9993 3,4</sup>
    </p>
    <!-- affiliations -->
    <p class="subtitle is-5"> 
      <sup>1</sup> Fudan Unversity,
      <sup>2</sup> Shanghai Jiao Tong University,
      <sup>3</sup> The Chinese University of Hong Kong, 
      <br>
      <sup>4</sup> Shanghai AI Laboratory,
      <sup>5</sup> S-Lab, Nanyang Technological University
      <sup>6</sup> Stanford University
    </p>
    <p class="subtitle is-5"> 
      <b>*</b> Equal Contribution &nbsp;&nbsp;&nbsp
      <b><sup>&#9993</sup></b> Corresponding author
    </p>
    <br>
    <!-- other links -->
    <div class="is-flex is-justify-content-center">
      <span class="icon-text mx-1">
        <a class="button is-dark" href="https://arxiv.org/abs/2312.04543" role="button" target="_blank"> <span class="icon"> <ion-icon name="document-outline"></ion-icon> </span> <span> Paper </span>  </a>
      </span>
      <span class="icon-text mx-1">
        <a class="button is-dark" href="https://github.com/wutong16/HyperDreamer" role="button" target="_blank"> <span class="icon"> <ion-icon name="logo-github"></ion-icon> </span> <span> Code </span> </a>
      </span>
      <span class="icon-text mx-1">
        <a class="button is-dark" target="_blank"> <span class="icon"> <ion-icon name="color-wand-outline"></ion-icon> </span> <span> Demo(Coming Soon) </span> </a>
      </span>
    </div><br>
   
  </div>

  <!-- main container -->
  <div class="container is-max-desktop has-text-centered">
    <!-- abstract -->
    <p class="title is-3 mt-5 has-text-centered"> Abstract </p>
    <p class="content is-size-6 has-text-left">
    <img src="images/teaser.png" height="150%" style="margin-left: auto;margin-right: auto;display: block;"/></p>
    <p align="left">
      Physically realistic materials are pivotal in augmenting the realism of 3D assets across various applications and lighting conditions. However, existing 3D assets and generative models often lack authentic material properties. Manual assignment of materials using graphic software is a tedious and time-consuming task. 
      In this paper, we exploit advancements in Multimodal Large Language Models (MLLMs), particularly GPT-4V, to present a novel approach, <b>Make-it-Real</b>: 
      <b>1)</b> We demonstrate that GPT-4V can effectively recognize and describe materials, allowing the construction of a detailed material library. 
      <b>2)</b> Utilizing a combination of visual cues and hierarchical text prompts, GPT-4V precisely identifies and aligns materials with the corresponding components of 3D objects. 
      <b>3)</b> The correctly matched materials are then meticulously applied as reference for the new SVBRDF material generation according to the original diffuse map, significantly enhancing their visual authenticity. 
      Make-it-Real offers a streamlined integration into the 3D content creation workflow, showcasing its utility as an essential tool for developers of 3D assets.
    </p>


    <!-- results (videos) -->
    <p class="title is-3 mt-5 has-text-centered"> Video </p>
    <div class="publication-video">
      <!-- <iframe src="https://www.youtube.com/embed/UAUJNFJSbiI?rel=0&amp;showinfo=0"
              frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
      <iframe src="https://www.youtube.com/embed/aOPP9_dmOuY?rel=0&amp;showinfo=0"
              frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div><br>
    <!-- <p class="title is-3 mt-5 has-text-centered"> Method Overview </p>
    <img src="images/library.png" height="150%" style="margin-left: auto;margin-right: auto;display: block;"/></p><br> -->

    <!-- <p align="left">
      <b>Overall pipeline.</b> This pipeline of Make-it-Real is composed of Multi-View Image Segmentation, MLLM-based Material Matching, and SVBRDF Maps Generation.
    </p> -->

    <p class="title is-3 mt-5 has-text-centered"> PBR-Texture Generation on Objaverse 3D assets </p>
    <div class="my-video-row">
      <!-- 循环4次，每个 container 对应一个视频和滑块 -->
      <div class="my-video-container" id="container1_1">
          <div class="my-video-video-container">
              <video class="my-video-video" src="videos/truck/truck_1.mp4" autoplay loop muted></video>
              <video class="my-video-video" src="videos/truck/truck_ori.mp4" autoplay loop muted></video>
          </div>
          <div class="my-video-slider"></div>
      </div>
      <div class="my-video-container" id="container1_2">
          <div class="my-video-video-container">
              <video class="my-video-video" src="videos/cup/cup_1.mp4" autoplay loop muted></video>
              <video class="my-video-video" src="videos/cup/cup_ori.mp4" autoplay loop muted></video>
          </div>
          <div class="my-video-slider"></div>
      </div>
      <div class="my-video-container" id="container1_3">
          <div class="my-video-video-container">
              <video class="my-video-video" src="videos/boot/boots_1.mp4" autoplay loop muted></video>
              <video class="my-video-video" src="videos/boot/boots_ori.mp4" autoplay loop muted></video>
          </div>
          <div class="my-video-slider"></div>
      </div>
      <div class="my-video-container" id="container1_4">
          <div class="my-video-video-container">
              <video class="my-video-video" src="videos/phone/phone_1.mp4" autoplay loop muted></video>
              <video class="my-video-video" src="videos/phone/phone_ori.mp4" autoplay loop muted></video>
          </div>
          <div class="my-video-slider"></div>
      </div>
    </div>
    <div class="my-video-row">
      <!-- 循环4次，每个 container 对应一个视频和滑块 -->
      <div class="my-video-container" id="container2_1">
          <div class="my-video-video-container">
              <video class="my-video-video" src="videos/bath/bath.mp4" autoplay loop muted></video>
              <video class="my-video-video" src="videos/bath/bath_ori.mp4" autoplay loop muted></video>
          </div>
          <div class="my-video-slider"></div>
      </div>
      <div class="my-video-container" id="container2_2">
          <div class="my-video-video-container">
              <video class="my-video-video" src="videos/globe/globe.mp4" autoplay loop muted></video>
              <video class="my-video-video" src="videos/globe/globe_ori.mp4" autoplay loop muted></video>
          </div>
          <div class="my-video-slider"></div>
      </div>
      <div class="my-video-container" id="container2_3">
          <div class="my-video-video-container">
              <video class="my-video-video" src="videos/vase/vase.mp4" autoplay loop muted></video>
              <video class="my-video-video" src="videos/vase/vase_ori.mp4" autoplay loop muted></video>
          </div>
          <div class="my-video-slider"></div>
      </div>
      <div class="my-video-container" id="container2_4">
          <div class="my-video-video-container">
              <video class="my-video-video" src="videos/gun/gun.mp4" autoplay loop muted></video>
              <video class="my-video-video" src="videos/gun/gun_ori.mp4" autoplay loop muted></video>
          </div>
          <div class="my-video-slider"></div>
      </div>
    </div>

    <p class="title is-3 mt-5 has-text-centered"> PBR-Texture Generation on Generated 3D Object </p>


    <p class="title is-3 mt-5 has-text-centered"> Method Overview </p>
    <img src="images/pipeline.png" height="150%" style="margin-left: auto;margin-right: auto;display: block;"/></p><br>

    <p align="left">
      <b>Overall pipeline.</b> This pipeline of Make-it-Real is composed of Multi-View Image Segmentation, MLLM-based Material Matching, and SVBRDF Maps Generation.
    </p>

    <p class="title is-3 mt-5 has-text-centered"> Material Library </p>
    <img src="images/lib.png" height="150%" style="margin-left: auto;margin-right: auto;display: block;"/></p><br>

    <p align="left">
      <b> Material Library.</b> Utilizing GPT-4V
      model, we develop a material library, meticulously generating and cataloging comprehensive descriptions for each material. This structured repository facilitates hierarchical
      querying for material allocation in subsequent looking up processes.
    </p>
    <!-- <p class="title is-3 mt-5 has-text-centered"> Relighting </p>
    <video muted autoplay loop> <source src="videos/relighting_rgb.mp4" type="video/mp4"> </video>
     -->
    <!-- <p class="title is-3 mt-5 has-text-centered"> Interactive Editing  </p>
    <p class="content has-text-centered is-size-5">
      For a generated model or their own data, users can interactively select any region via a few clicks 
      and efficiently edit the texture with text-based guidance.
    </p>
    <video muted autoplay loop> <source src="videos/editing1.mp4" type="video/mp4"> </video>
    <video muted autoplay loop> <source src="videos/editing2.mp4" type="video/mp4"> </video>
    <video muted autoplay loop> <source src="videos/editing3.mp4" type="video/mp4"> </video> -->

    <!-- <p class="title is-3 mt-5 has-text-centered"> Optimization Progress </p>
    <table class="table">
      <tbody>
        <tr> 
          <th> <video muted controls autoplay loop> <source src="videos/gui.mp4" type="video/mp4"> </video> </th>
          <th> <video muted controls autoplay loop> <source src="videos/gui2.mp4" type="video/mp4"> </video> </th>
        </tr>
        <tr>
          <th class="has-text-centered"> Stage 1 (Generative Gaussian Splatting) </th>
          <th class="has-text-centered"> Stage 2 (Mesh Texture Refinement) </th>
        </tr>
    </table>
    <p class="content has-text-centered is-size-5">
      Videos are played at the original speed and recorded on an NVIDIA 3070 (8GB).
    </p> -->
    
    <!-- 3d model viewer -->
    <!-- <p class="title is-3 mt-5 has-text-centered"> Exported Meshes </p>
    <div class="level">
      <div class="level-item">
        <model-viewer src="meshes/anya.glb" poster="meshes/anya.jpg" style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
      <div class="level-item">
        <model-viewer src="meshes/luigi.glb" poster="meshes/luigi.jpg" style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
      <div class="level-item">
        <model-viewer src="meshes/zelda.glb" poster="meshes/zelda.jpg" style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
      <div class="level-item">
        <model-viewer src="meshes/toy.glb" poster="meshes/toy.jpg" style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
    </div>
    
    <p class="title is-3 mt-5 has-text-centered"> Mesh Animations </p>
    <p class="content has-text-centered is-size-5">
      The following results are animated by <a href="https://www.mixamo.com/">Mixamo</a>.
    </p>
    <div class="level">
      <div class="level-item">
        <model-viewer src="meshes/rabbit_animate.glb" poster="meshes/toy2.jpg" style="width: 100%; height: 300px;" autoplay shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
      <div class="level-item">
        <model-viewer src="meshes/girl_animate.glb" poster="meshes/girl_animate.png" style="width: 100%; height: 300px;" autoplay shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
      <div class="level-item">
        <model-viewer src="meshes/boy_animate.glb" poster="meshes/boy_animate.png" style="width: 100%; height: 300px;" autoplay shadow-intensity="1" camera-controls touch-action="pan-y"></model-viewer>
      </div>
    </div> -->

    <!-- citation -->
    <div class="card mt-4">
      <header class="card-header">
        <p class="card-header-title"> Citation </p>
      </header>
      <div class="card-content is-size-5 has-text-left">
<pre><code>@InProceedings{wu2023hyperdreamer,
  author = {Tong Wu, Zhibing Li, Shuai Yang, Pan Zhang, Xingang Pan, Jiaqi Wang, Dahua Lin, Ziwei Liu},
  title = {HyperDreamer: Hyper-Realistic 3D Content Generation and Editing from a Single Image},
  journal={ACM SIGGRAPH Asia 2023 Conference Proceedings},
  year={2023}
}</code></pre>
      </div>
    </div>
  </div>


  </section>
<p>
<!-- <link rel="stylesheet" href="styles.css"> -->

</div>
</p>
<div class="center-text">
<!-- <a href="https://clustrmaps.com/site/1bzgi"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=uVAj7gydWIyD0AQWR3NPboT8GvHlNvMR9cAYCUq58m0&cl=ffffff" /></a> -->
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=600&t=tt&d=uVAj7gydWIyD0AQWR3NPboT8GvHlNvMR9cAYCUq58m0&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
</div>
<script src="script.js"></script>
</body>
</html>
