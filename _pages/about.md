---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a second-year Ph.D. student in Shanghai Jiao Tong University.
I abtain my Bachelor's degree in Computer Science from Beihang University in 2023.

My research interest includes multimodal learning, RL and Generative AI.



# üî• News
- [2025-06-26] BootStrap3D, Visual-RFT, X-Prompt are accepted by ICCV 2025.
- [2024-09-28] Make-it-Real is accepted by NeurIPS 2024.
- [2024-03-02] Alpha-CLIP, GPT4Point are accepted by CVPR 2024.


# üìù Selected Publications (* Equal Contribution)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='images/Visual-RFT.png' alt="Visual-RFT" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Visual-RFT: Visual Reinforcement Fine-Tuning](https://github.com/Liuziyu77/Visual-RFT)

Ziyu Liu*, **Zeyi Sun\***, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin, Jiaqi Wang

**[ICCV 2025]**

<span> Early Exploration of Deepseek-R1's RL strategy to the multimodal field</span>

[Github ![](https://img.shields.io/github/stars/Liuziyu77/Visual-RFT)](https://github.com/Liuziyu77/Visual-RFT) | [Arxiv ![](https://img.shields.io/github/stars/SunzeY/AlphaCLIP)](https://arxiv.org/abs/2312.03818)
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='images/Visual-RFT.png' alt="Visual-RFT" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[Alpha-CLIP: A CLIP Model Focusing on Wherever Your Want](https://github.com/Liuziyu77/Visual-RFT)

**Zeyi Sun\***, Ye Fang*, Tong Wu, Pan Zhang, Yuhang Zang, Shu Kong, Yuanjun Xiong, Dahua Lin, Jiaqi Wang

**[CVPR 2024] Strong Accept By All Reviewers**

<span> Region Level Contrastive Learning Fundation model based on CLIP.</span>

[Github ![](https://img.shields.io/github/stars/SunzeY/AlphaCLIP)](https://github.com/SunzeY/AlphaCLIP) | 
[Arxiv ![](https://img.shields.io/github/stars/SunzeY/AlphaCLIP)](https://arxiv.org/abs/2312.03818)
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='images/MIA-DPO.png' alt="MIA-DPO" width="100%"></div></div>
<div class='paper-box-text' markdown="1">


[RAR:Retrieving And Ranking Augmented MLLMs for Visual Recognition](https://arxiv.org/abs/2403.13805)

***Ziyu Liu***, Zeyi Sun, Yuhang Zang, Wei Li, Pan Zhang, Xiaoyi Dong, Yuanjun Xiong, Dahua Lin, Jiaqi Wang

<span> Combining retrieving and ranking with multi-modal large language models to revolutionize perception tasks such as fine-grained recognition, zero-shot image recognition, and few-shot object recognition. Our method opens up new avenues for research in augmenting the MLLM‚Äôs abilities with the retrieving-augmented solution and could be beneficial for other tasks such as reasoning and generation in future works.</span>

[**Github** ![](https://img.shields.io/github/stars/Liuziyu77/RAR)](https://github.com/Liuziyu77/RAR)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='images/MMlong.png' alt="RAR" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

</div>


# üéñ Honors and Awards
- *2024.06*, Excellent Bachelor's ThesisÔºåOutstanding Undergraduate Graduate.
- *2023.07*, Meritorious Award, Mathematical Contest in Modeling and Interdisciplinary Contest in Modeling (MCM/ICM), COMAP.
- *2022.05*, National Second Prize, China Undergraduate Mathematical Contest in Modeling(CUMCM), China Society for Industrial and Applied Mathematics(CSIAM).
- *2022.05*, Finalist Award, Mathematical Contest in Modeling and Interdisciplinary Contest in Modeling (MCM/ICM), COMAP.

# üìñ Educations
- *2023.09 - until now*, P.HD., Shanghai Jiao Tong University.
- *2019.09 - 2023.06*, Bachelor's degree, Beihang University

# üìå Services
- Conference reviewer of CVPR, ICCV, ICML, Neurips.
- Workshop organizing community of <a href='https://vplow.github.io/vplow_4th.html'>VPLOW@CVPR2024</a>.
- S.T.A.R teaching assistant of OS-2022-Spring in CS department founded by [Qian Liu](https://siviltaram.github.io/).